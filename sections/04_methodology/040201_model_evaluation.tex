\documentclass[../../main.tex]{subfiles}
\begin{document}
% START SKRIV HER

\section{Model Evaluation}

\subsection{Classification}
A commonly used method of evaluation classification models is via a confusion matrix. It compares predictions against actual observations. In our case, predicting out-of-stock is defined as the positive class. From the confusion matrix, we get the false positives (the item was predicted to go out-of-stock, but it was in-stock), true positives (the item was predicted to go out-of-stock and actually did), false negatives (the item was predicted to be in-stock, but it went out-of-stock) and true negatives (it was predicted to be in-stock and did not go out-of-stock). This method is highly intuitive and valuable in a business setting. One can attribute a cost to each of the cases, and calculate a model's profit. The overall ccuracy is the most basic performance measure and is defined as 

Accuracy = TP + TN / TP + TN + FP + FN.

Confusion matrix with positive class on the right side.

%%%%%%

\documentclass[11pt]{report}
\usepackage{graphicx}

%%%% Confusion Matrix Body %%%%
\newcommand\MyBox[1]{%
  \fbox{\parbox[c][1.7cm][c]{1.7cm}{\centering #1}}%
  % Size of boxes
}
\newcommand\MyVBox[1]{%
  \parbox[c][1cm][c]{1cm}{\centering\bfseries #1}%
}  
\newcommand\MyHBox[2][\dimexpr1.7cm+2\fboxsep\relax]{%
  \parbox[c][1cm][c]{#1}{\centering\bfseries #2}%
}  
\newcommand\MyTBox[4]{%
  \MyVBox{#1}
  \MyBox{#2}\hspace*{-\fboxrule}%
  \MyBox{#3}\par\vspace{-\fboxrule}%
}  
%%%%
\newcommand*\rot{\rotatebox{90}}

\begin{document}


\begin{figure}
\begin{center}
{

\offinterlineskip

\raisebox{-5cm}[0pt][0pt]{
\parbox[c][0pt][c]{0cm}{\hspace{-3.5cm}\rot{\textbf{Actual}}\\[20pt]}}\par

\hspace*{1cm}\MyHBox[\dimexpr3.4cm+6\fboxsep\relax]{Predicted}\par

\hspace*{1cm}\MyHBox{30}\MyHBox{90}\par

\MyTBox{30}{9418}{1471}

\MyTBox{90}{144}{317}

}
\end{center}
\end{figure}
\end{document}

%%%%%%

\subsubsection{Precision and Recall}
Precision and recall measures different types of errors, and are useful when the two represent different costs (James et al, 2013). Precision is the accuracy of predicting the positive class. In our case, when we predict a stockout, how accurate are we? Formally, it is written as 

Precision = TP / TP + FP

Recall measures how effective the model is at detecting the positive class:

Recall = TP / TP + FN.

When predicting stockouts, recall measures how skilled the model is at detecting a stockout. Combined, they represent a trade-off, where precision is defined as one minus recall. This is especially relevant if the dataset is imbalanced. For instance, since stockouts occur in 30\% of the products, a model that always predicts that a product will go out-of-stock will achieve an overall accuracy of 70\%, even though the model does not represent any skill. It is as good as guessing.

\subsubsection{Receiver Operating  Characteristic (ROC) Curve}
A Receiver Operating Curve (ROC) is often recommended in a classification setting because it controls for class imbalances (Bradley, 1997). It is represented by a quadratic square, where the false positive rate is measured on the $X$-axis, while the true positive rate is measured on the $Y$-axis. A diagonal represents a model with no skill, ie. this accuracy would be achieved by predicting the most common class. The two dimensions represents the trade-off between the false positive rate and the true positive rate. The trade-offs are represented by the ROC curve, and are achieved by using a different threshold for converting probabilities to classifications. It follows that an optimal threshold can be achieved along any point on the ROC curve, depending on the cost associated by the different errors. A model has more skill if the ROC curve moves closer to the corner such that the area under the ROC curve increases. Hence, the area under the ROC curve is considered a good measure for a classification model (James et al., 2013).

Bradley 1997: https://www.sciencedirect.com/science/article/pii/S0031320396001422

\subsection{Regression}
Machine learning models use a loss function that penalizes errors when training. It follows that the choice of loss function will affect how the model learns. For a regression problem, the most common evaluation methods are root mean squared error (RMSE) and mean absolute error (MAE). Mean absolute error is defined as 

MAE = 1 / N sum(abs(yhat - y)),

while RMSE is defined as

$RMSE = sqrt(1 / N(sum(yhat - y)^2)).$

For our problem, we choose RMSE as the loss function. The reason is that RMSE penalized large deviations more than small deviations, which has substantial impact on our business problem. In our dataset, products with a larger stockout quantity is intuitively products that sell more, ie. more popular products. It could be argued that these products have a higher impact, as they sell more and the company can delight more customers with these products. In comparison, a book about flowers written in Old English that sells one unit a year is not that important to the company. As a consequence, we want to avoid large deviations, as this means a higher error for the most popular products.

% SLUTT SKRIV HER
\end{document}